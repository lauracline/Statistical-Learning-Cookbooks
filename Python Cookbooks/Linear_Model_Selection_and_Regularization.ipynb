{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Model Selection and Regularization",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/wFqahh0E632ea1yWgDJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauracline/Statistical-Learning-Cookbooks/blob/master/Linear_Model_Selection_and_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-CpP3TDmqBV"
      },
      "source": [
        "# **Chapter Six: Linear Model Selection and Regularization** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwbN0SImzpM"
      },
      "source": [
        "Linear models still do astonishinlgy well compared to non-linear modles. This chapter will explore other types of fitting besides least squares because they can given better prediction accuracy and interpretability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCe7h3Fpm9EZ"
      },
      "source": [
        "## **Classes of Alternatives to Least Squares**\n",
        "\n",
        "1. Subset Selection: Choose of a subset of the predictors\n",
        "2. Shrinkage (Regularization): Fit all predictors but limit their size. Coefficients can go to 0. \n",
        "3. Dimension Reduction: project the predictors into a smaller subspace. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erUXH2ZgnNQX"
      },
      "source": [
        "## **Best Subset Selection**\n",
        "\n",
        "Fit all the possible models $2^{p}$ and take the one with the highest adjusted $R^{2}$ through cross validation. This can be impossible with a large enough p. \n",
        "\n",
        "## **Stepwise Selection - Forward, Backward and Both**\n",
        "\n",
        "Because of computational limitation a simpler method of adding or subtracting the best predictor to the current model is employed. \n",
        "\n",
        "### **Forward Selection**\n",
        "\n",
        "Start with an empty model and choose a predictor to add to the model based on the best adjusted $R^{2}$ or other similiar metric. Continue adding variables until no improvement in adjusted $R^{2}$. \n",
        "\n",
        "A variation of this is to retain each model at each step and use $R^{2}$ (not adjusted) as the metric. This will build p models. Then use cross validation witth $R^{2}$ to pick the best model of those p models built from forward selection. \n",
        "\n",
        "### **Backward Selection**\n",
        "\n",
        "Similiar to forward selection but start with all predictors in the model and remove one at a time until adjusted $R^{2}$ is maximized or alternatively, find p models with $R^{2}$ and then use cross validation to pick the best of the p models. \n",
        "\n",
        "### **Both**\n",
        "\n",
        "At each step, consider both adding or subtracting a variable in the model. \n",
        "\n",
        "## **Choosing Optimal Model**\n",
        "\n",
        "### **Adjusting Training Statistics or Using Cross Validation** \n",
        "\n",
        "As learned in Chapter 5, cross validation is an extremely good tool at giving us insight to how well the model will be used on unseen data (test data). \n",
        "\n",
        "But alternatively to cross validation, we can punish the training error statistics so in theory they can give us insight on what the test error will be. There have been several statistics developed to give us insight as to what the model will do for unseen errors. \n",
        "\n",
        "The four most popular are AIC, BIC, Mallows Cp, and Adjusted $R^{2}$. AIC, BIC and Cp all have similiar formulas that inflate the error for more predictors and a higher estimated varaince. Adjusted $R^{2}$ lowers the $R^{2}$ by each additional predictor in the model. All four of these statistics are 'classical' model selectors and were used before cross validation and so relied on just fitting the data one time on ALL the data. \n",
        "\n",
        "Cross validation can be computationally intense but with modern computation we can build lots of models and evaluate them easily. \n",
        "\n",
        "### **Shrinkage Methods**\n",
        "\n",
        "Ridge and Lasso regression are the most common. \n",
        "\n",
        "#### **Ridge Regression**\n",
        "\n",
        "Minmimizes not only the squared error (RSS) but sum of predictors squared times a constant $\\lambda$. When $\\lambda$ is 0 then ridge equals least squares, when $\\lambda$ heads to infinity, all predictors head to 0. \n",
        "\n",
        "Since ridge regression works directly with the size of the parameter coefficients, you must scale all the predictors by dividing by their standard deviation. \n",
        "\n",
        "#### **The Lasso**\n",
        "\n",
        "Uses L1 penalty instead of L2 (absolute value of predictors vs. squared value). The lasso performs variable selection by setting some predictors exacly 0 (and thus automatic variable selection), unlike ridge which will never completely eliminate variables. \n",
        "\n",
        "#### **Alternative Logic of Lasso and Ridge Regression**\n",
        "\n",
        "Instead of thinking of penalizing the error by either the L1 or L2 norm, we can think of setting up lasso/ridge regression as minimizing the squared errors subject to keeping the parameters less than a certain value. Think of this value as a 'budget' of allowable spending to occur. You can allow yourself to spend your parameters in any way you chose as long as you don't go over the total budget. \n",
        "\n",
        "Lasso yields predictors equivalent to 0 because of sharp corners. \n",
        "\n",
        "#### **What is Better, Lasso or Ridge?**\n",
        "\n",
        "No way to tell beforehand in general, in settings where they are many important predictor variables that related to the response, ridge regression will perform better. When there are only a few variables related to the response, then lasso will do better. \n",
        "\n",
        "But...as always cross validation can be used. \n",
        "\n",
        "#### **Choosing Lambda**\n",
        "\n",
        "Choos $\\lambda$ through cross validation. Search an array of $\\lambda$'s through cross validation and choose the $\\lambda$ which minimizes MSE. Then build your model with that $\\lambda$ on all the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVC9wpxQqxOM"
      },
      "source": [
        "## **Dimension Reduction Techniques**\n",
        "\n",
        "Instead of using the origianl predictors, we transform then first and then fit our models. Usually we transform variables so that there are less in number than the original set. Two approaches are recommended - principal components and partial least squares. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVYn5aP9rEKk"
      },
      "source": [
        "### **Principal Component Analysis (PCA)**\n",
        "\n",
        "The first principal component is the direction where observations vary the most. We want to capture as much information as we can in one single direction. Which single direction captures as much information as possible? The direction where the variance is highest amongest the projected points. \n",
        "\n",
        "The first principal components also minimizes the sum of squared perpendicular distances between point and line. Each transformed first principal component can be thought as single number summaries of all that particular observation.\n",
        "\n",
        "The second principal component must be uncorrelated to the first which makes it orthogonal (90 degrees in two dimensions) to the first. The second principal component will capture less information (less spread). Plotting each principal component against each variable can show how much information is captured by each one. \n",
        "\n",
        "#### **Principal Component Regression**\n",
        "\n",
        "First find the first M principal components where M < p then fit with least squares. Choose M with cross validation. Usually, data is standardized by standard deviation first. \n",
        "\n",
        "#### **Partial Least Squares**\n",
        "\n",
        "The response does not determine the principal components. This means PCA is used in an unsupervised way. PLS is a supervised alternative to PCR. PLS generates new features as a linear combination of the old features and the response. \n",
        "\n",
        "Computed by doing simple linear regression of Y onto each predictor and setting that coefficient to the linear combination coefficient for transformed variable Z1. So weights are higher for those variables with stronger relationships to response. Z2 is computed by regressing all variables against the residuals of Z1 being fit to the model. Do this iteratively (fit remaining residuals) to come up with M PLS components. Then do least squares fit on all M new dimensions. In practice, PLS does not do better than PCR or ridge regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqos2l-psuIq"
      },
      "source": [
        "## **High Dimensional Data**\n",
        "\n",
        "When speaking of high dimensional data, we generally mean data with many predictors, especially when p approaches or exceeds n. Generally it is better to have more predictors but if many of the predictors are not associated with the response then they can cause the actual signal to get diluted - a double edged sword these predictors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F7RPhGEs_p2"
      },
      "source": [
        "## **Excercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwsF9oYAtO7m"
      },
      "source": [
        "### **Question Eight**\n",
        "\n",
        "In this excercise, we will generate simulated data, and will then use this data to perform best subset selection. \n",
        "\n",
        "A. Use the random function to generate a predictor X of length n = 100 as well as a noise vector $\\epsilon$ of length n = 100. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cD8PmTtmNq"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "import matplotlib as plt\n",
        "%matplotlib inline "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJjYCKs3tg5v"
      },
      "source": [
        "x = np.random.randn(100)\n",
        "err = np.random.randn(100)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luU0bGOPuaCC"
      },
      "source": [
        "B. Generate a response vector y of length n = 100 according to the model $Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}X^{2} + \\beta_{3}X^{3} + \\epsilon$, where $\\beta_{0}$, $\\beta_{1}$, $\\beta_{2}$, and $\\beta_{3}$ are constants of your choice. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7WjvAsMuK3w"
      },
      "source": [
        "beta0, beta1, beta2, beta3 = -5, 1, 4, 3\n",
        "y = beta0 + beta1 * x + beta2 * x ** 2 + beta3 * x ** 3 + err"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGvpqaXu49o"
      },
      "source": [
        "C. Perform best subset selection in order to choose the best model containing the predictors $X$, $X^{2}$,...,$X^{10}$. What is the best model obtained according to $C_{p}$, BIC, and adjusted $R^{2}$? Show some plots to provide evidence for your answer and report the coefficients of the best model obtained. You will also need to create a single dataset containing both X and y. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzdb7TS4vQ3A"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from itertools import combinations\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEINJNA1vcRy",
        "outputId": "d64565b5-c6dc-4222-974c-c4475bbe1c0e"
      },
      "source": [
        "OrderedDict({'b': 1, 'a':534})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('b', 1), ('a', 534)])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZzH8P1Avi4R"
      },
      "source": [
        "df = pd.DataFrame({'x1': x, 'x2': x ** 2, 'x3': x**3, 'x4': x**4,'x5': x**5,\n",
        "                   'x6': x**6,'x7': x**7,'x8': x**8,'x9': x**9,'x9_10': x**10,\n",
        "                   'y':y})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SKy4BFz8vw-p",
        "outputId": "2b44e012-c204-4dfc-d452-606d6ce0478b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x9_10</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.613976</td>\n",
              "      <td>6.832871</td>\n",
              "      <td>17.860960</td>\n",
              "      <td>46.688121</td>\n",
              "      <td>122.041628</td>\n",
              "      <td>3.190139e+02</td>\n",
              "      <td>8.338947e+02</td>\n",
              "      <td>2.179781e+03</td>\n",
              "      <td>5.697894e+03</td>\n",
              "      <td>1.489416e+04</td>\n",
              "      <td>79.353933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.545026</td>\n",
              "      <td>0.297053</td>\n",
              "      <td>0.161902</td>\n",
              "      <td>0.088241</td>\n",
              "      <td>0.048093</td>\n",
              "      <td>2.621213e-02</td>\n",
              "      <td>1.428629e-02</td>\n",
              "      <td>7.786396e-03</td>\n",
              "      <td>4.243787e-03</td>\n",
              "      <td>2.312973e-03</td>\n",
              "      <td>-3.869276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.079278</td>\n",
              "      <td>0.006285</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>2.482622e-07</td>\n",
              "      <td>1.968169e-08</td>\n",
              "      <td>1.560322e-09</td>\n",
              "      <td>1.236989e-10</td>\n",
              "      <td>9.806585e-12</td>\n",
              "      <td>-5.045381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.945112</td>\n",
              "      <td>0.893236</td>\n",
              "      <td>-0.844207</td>\n",
              "      <td>0.797870</td>\n",
              "      <td>-0.754076</td>\n",
              "      <td>7.126863e-01</td>\n",
              "      <td>-6.735680e-01</td>\n",
              "      <td>6.365969e-01</td>\n",
              "      <td>-6.016551e-01</td>\n",
              "      <td>5.686312e-01</td>\n",
              "      <td>-4.394567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.127330</td>\n",
              "      <td>4.525533</td>\n",
              "      <td>-9.627302</td>\n",
              "      <td>20.480449</td>\n",
              "      <td>-43.568674</td>\n",
              "      <td>9.268495e+01</td>\n",
              "      <td>-1.971715e+02</td>\n",
              "      <td>4.194488e+02</td>\n",
              "      <td>-8.923060e+02</td>\n",
              "      <td>1.898229e+03</td>\n",
              "      <td>-18.139573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x1        x2         x3  ...            x9         x9_10          y\n",
              "0  2.613976  6.832871  17.860960  ...  5.697894e+03  1.489416e+04  79.353933\n",
              "1  0.545026  0.297053   0.161902  ...  4.243787e-03  2.312973e-03  -3.869276\n",
              "2  0.079278  0.006285   0.000498  ...  1.236989e-10  9.806585e-12  -5.045381\n",
              "3 -0.945112  0.893236  -0.844207  ... -6.016551e-01  5.686312e-01  -4.394567\n",
              "4 -2.127330  4.525533  -9.627302  ... -8.923060e+02  1.898229e+03 -18.139573\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZLNvO8ovyr6"
      },
      "source": [
        "lr = LinearRegression()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dj5dHVSv0ld"
      },
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df['y']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEqU8_IJv9XK",
        "outputId": "d4d47327-135e-4e22-e812-c8fcf1673056"
      },
      "source": [
        "lr.fit(X,y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-hcWm6Lv_GN"
      },
      "source": [
        "sigma2 = np.sum((lr.predict(X) - y) ** 2) / len(X)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "VX16UBuUwEkQ",
        "outputId": "1f0f8b08-67ee-46d6-d068-211c8412ae58"
      },
      "source": [
        "# Best subset selection \n",
        "n = len(X)\n",
        "idx = pd.IndexSlice\n",
        "cp = []\n",
        "bic = []\n",
        "adj_r2 = []\n",
        "for i in range(1, 11):\n",
        "    current_cp = []\n",
        "    current_bic = []\n",
        "    current_adj_r2 = []\n",
        "    for comb in combinations(range(10), i):\n",
        "        X = df.iloc[:,comb]\n",
        "        lr.fit(X, y)\n",
        "        rss = np.sum((lr.predict(X) - y) ** 2)\n",
        "        tss = np.sum((y - y.mean()) ** 2)\n",
        "        d = len(comb)\n",
        "        current_cp.append(1/n * (rss + 2 * d * sigma2))\n",
        "        current_bic.append(1/n * (rss + np.log(n) * d * sigma2))\n",
        "        current_adj_r2.append(1 - rss / (n - d - 1) * (n - 1) / tss)\n",
        "        \n",
        "    cp.append(min(current_cp))\n",
        "    bic.append(min(current_bic))\n",
        "    adj_r2.append(max(current_adj_r2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8b379dbeb520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcurrent_adj_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;31m# so don't treat a tuple as a valid indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "bIoSNH5XyDRR",
        "outputId": "33eae2c9-374d-4eec-80fc-7fc5dca5e71e"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1, 11), cp)\n",
        "plt.plot(range(1, 11), bic)\n",
        "plt.title(\"CP and BIC Best subset\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b840b4fd8445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CP and BIC Best subset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "nYj3pspwAdR3",
        "outputId": "56551a1d-db04-4a28-8aee-886bd85dab7f"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,11), adj_r2)\n",
        "plt.title(\"Adjusted R^2\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1cf281c9cb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adjusted R^2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "9Z8TV1alBFD9",
        "outputId": "1f6a7f5e-a022-4b5d-a46d-4b6f1baa0941"
      },
      "source": [
        "# all three agree on the correct model\n",
        "np.argmin(cp), np.argmin(bic), np.argmin(adj_r2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1b985f4ab2c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# all three agree on the correct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \"\"\"\n\u001b[0;32m-> 1269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kccQVDfvQXl"
      },
      "source": [
        "D. Repeat (C), using forward stepwise selection and also using backwards stepwise selection. How does your answer compare to the results in (C)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQu973HfBV_u"
      },
      "source": [
        "# Forward selection. Looks at Cp each step and stops \n",
        "# if it can't beat old best\n",
        "current_vars = []\n",
        "best_cp = 10000000\n",
        "prev_cp = best_cp\n",
        "best_cp = 1000000\n",
        "while best_cp < prev_cp:\n",
        "    prev_cp = best_cp\n",
        "    old_vars = current_vars.copy()\n",
        "    for i in range(10):\n",
        "        if i in current_vars:\n",
        "            continue\n",
        "        X = df.iloc[:, old_vars + [i]]\n",
        "        lr.fit(X, y)\n",
        "        rss = np.sum((lr.predict(X) - y) ** 2)\n",
        "        d = len(old_vars) + 1\n",
        "        cur_cp = 1/n * (rss + 2 * d * sigma2)\n",
        "        if cur_cp < best_cp:\n",
        "            current_vars = old_vars + [i]\n",
        "            best_cp = cur_cp"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-7jjGzmCPNt",
        "outputId": "ec3f0cb8-4ef4-4c21-a0b7-2d70ba26b1ab"
      },
      "source": [
        "current_vars"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0VmGzcVCQ1Y",
        "outputId": "0ec96b85-f92b-486f-99bc-0886e3062297"
      },
      "source": [
        "best_cp"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7397476891323536"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoSwfdyMCVYx",
        "outputId": "1572bbc9-772e-4933-c944-98d909b107b1"
      },
      "source": [
        "old_vars"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb8iBZ4SCX1L"
      },
      "source": [
        "# Backward stepwise selection. Looks at Cp each steps and stops if it\n",
        "# can't beat the old best\n",
        "\n",
        "current_vars = list(range(10))\n",
        "best_cp = 10000000\n",
        "prev_cp = best_cp\n",
        "best_cp = 1000000\n",
        "while best_cp < prev_cp:\n",
        "    prev_cp = best_cp\n",
        "    old_vars = current_vars.copy()\n",
        "    for i in range(10):\n",
        "        if i not in current_vars:\n",
        "            continue\n",
        "        old_vars2 = old_vars.copy()\n",
        "        old_vars2.remove(i)\n",
        "        X = df.iloc[:, old_vars2]\n",
        "        lr.fit(X, y)\n",
        "        rss = np.sum((lr.predict(X) - y) ** 2)\n",
        "        d = len(old_vars) + 1\n",
        "        cur_cp = 1/n * (rss + 2 * d * sigma2)\n",
        "        if cur_cp < best_cp:\n",
        "            current_vars = old_vars2.copy()\n",
        "            best_cp = cur_cp"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWJm0CwgCfeN",
        "outputId": "7a6c3351-f2e1-4c4a-9ee3-3e871fe073d1"
      },
      "source": [
        "current_vars # Different answer for backward selection "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBll_l1KCr1m"
      },
      "source": [
        "E. Now fit a lasso model to the simulated data, again using $X$, $X^{2}$,...,$X^{10}$ as predictors. Use cross-validation to select the optimal value of $\\lambda$. Create plots of the cross-validation error as a function of $\\lambda$. Report the resulting coefficient estimates, and discuss the results obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV9LXudaDC9h"
      },
      "source": [
        "X = df.iloc[:, :-1]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SncHPvgRDGHC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP0kHeQUDRYw"
      },
      "source": [
        "X_stand = X / X.std()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VphhI_WdDUY2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_stand, y)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBVYjOBED8UE"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qx5FdoNlDZoO",
        "outputId": "a80bd1eb-e112-4b79-d1c8-2e68c4584ad6"
      },
      "source": [
        "alphas = np.linspace(.0001, .1, 1000)\n",
        "errors = []\n",
        "for alpha in alphas:\n",
        "    ls = Lasso(alpha, max_iter=100000, tol=.0001)\n",
        "    ls.fit(X_train, y_train)\n",
        "    errors.append(np.mean((ls.predict(X_test) - y_test) ** 2))\n",
        "\n",
        "plt.plot(alphas, errors)\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69EjOkE6Dtof",
        "outputId": "d36e0d6d-f043-42a3-b729-453558f76b33"
      },
      "source": [
        "np.argmin(errors)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "212"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoPkcooSEJX1",
        "outputId": "9b845ae2-731d-4a06-dc28-cfb991be5737"
      },
      "source": [
        "alphas[53]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0054"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZscvgHILELGC",
        "outputId": "1697fb6d-2434-47cf-c4ed-16463ef69bd9"
      },
      "source": [
        "ls = Lasso(alpha = 0.0054, max_iter=100000, tol = 0.0001)\n",
        "ls.fit(X_stand, y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.0054, copy_X=True, fit_intercept=True, max_iter=100000,\n",
              "      normalize=False, positive=False, precompute=False, random_state=None,\n",
              "      selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41eVQJJIETX4",
        "outputId": "943f60ca-7a16-47b4-87be-794efd58719e"
      },
      "source": [
        "ls.intercept_, ls.coef_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.8647817922708665,\n",
              " array([ 1.11246616,  7.5847259 , 17.12427397, -0.        ,  0.        ,\n",
              "        -0.        ,  0.        , -0.        ,  0.03566276, -0.03684849]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlkdMJxqEWK2",
        "outputId": "725bedf5-56a0-42fa-b456-89d76044e186"
      },
      "source": [
        "# beta 3 was very far off\n",
        "beta0, beta1, beta2, beta3"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-5, 1, 4, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJx1zQFfEdBO"
      },
      "source": [
        "F. Now generate a response vector $Y$ according to the model \n",
        "\n",
        "$Y = \\beta_{0} + \\beta_{7}X^{7} + \\epsilon$,\n",
        "\n",
        "and perform best subset selection and the lasso. Discuss the results obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feW-w1BaEr9K"
      },
      "source": [
        "beta0_7 = 3\n",
        "beta7 = -1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ckj4u2Ev2r"
      },
      "source": [
        "y_7 = beta0_7 + beta7 * x ** 7 + err"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBmUAkiZE3Ab"
      },
      "source": [
        "df_7 = pd.DataFrame({'x1': x, 'x2': x ** 2, 'x3': x**3, 'x4': x**4,'x5': x**5,\n",
        "                   'x6': x**6,'x7': x**7,'x8': x**8,'x9': x**9,'x9_10': x**10,\n",
        "                   'y':y_7})"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "l01CjS99E5aG",
        "outputId": "71817d65-c417-42a7-b5af-42761f618b4f"
      },
      "source": [
        "plt.scatter(X['x7'], y_7)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f5435db1d50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "Pq9UXf0aFCZc",
        "outputId": "847928fb-cc99-4355-f632-9e5a784c1114"
      },
      "source": [
        "# Best subset selection \n",
        "\n",
        "\n",
        "# best subset selection\n",
        "X = df_7.iloc[:, :-1]\n",
        "n = len(X)\n",
        "tss = np.sum((y_7 - y_7.mean()) ** 2)\n",
        "lr.fit(X,  y_7)\n",
        "sigma2 = np.sum((lr.predict(X) - y_7) ** 2) / len(X)\n",
        "cp = []\n",
        "bic = []\n",
        "adj_r2 = []\n",
        "for i in range(1, 11):\n",
        "    current_cp = []\n",
        "    current_bic = []\n",
        "    current_adj_r2 = []\n",
        "    for comb in combinations(range(10), i):\n",
        "        X = df_7.iloc[:, comb]\n",
        "        lr.fit(X, y_7)\n",
        "        rss = np.sum((lr.predict(X) - y_7) ** 2)\n",
        "        \n",
        "        d = len(comb)\n",
        "        current_cp.append(1/n * (rss + 2 * d * sigma2))\n",
        "        current_bic.append(1/n * (rss + np.log(n) * d * sigma2))\n",
        "        current_adj_r2.append(1 - rss / (n - d - 1) * (n - 1) / tss)\n",
        "        \n",
        "    cp.append(min(current_cp))\n",
        "    bic.append(min(current_bic))\n",
        "    adj_r2.append(max(current_adj_r2))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ce84b567949b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcurrent_adj_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;31m# so don't treat a tuple as a valid indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "CZgA_WCFFdx2",
        "outputId": "cd4dcac5-78a7-4dcb-920c-f8f5c99c4f63"
      },
      "source": [
        "# Best model is with one predictor\n",
        "plt.plot(range(10), cp)\n",
        "bic.append(min(current_bic))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ce316a2a2fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best model is with one predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_bic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiPomsBYFkY8"
      },
      "source": [
        "# Lasso\n",
        "X = df_7.iloc[:, :-1]\n",
        "X_stand = X / X.std()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_stand, y_7)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9Ou11gFxAg"
      },
      "source": [
        "alphas = np.linspace(0.001, 50, 100)\n",
        "errors =[]\n",
        "la = Lasso(alpha, max_iter=1000000000, tol = 0.000001)\n",
        "\n",
        "for alpha in alphas:\n",
        "  ls = Lasso(alpha=alpha)\n",
        "  ls.fit(X_train, y_train)\n",
        "  errors.append(np.mean((ls.predict(X_test) - y_test)**2))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9Bo6YsLEGJ6C",
        "outputId": "b1a5a92b-8903-4ccb-991f-df1f6c30d6fa"
      },
      "source": [
        "plt.plot(alphas, errors)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5435d0ca10>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJyVaOyrGNnf",
        "outputId": "f03d79c3-f28b-4735-b432-0a0238743166"
      },
      "source": [
        "best_alpha = alphas[np.argmin(errors)]\n",
        "best_alpha"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.011080808080808"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_gePY-yGS9N",
        "outputId": "8e95d239-78fe-4c62-ebf0-a290cd049d04"
      },
      "source": [
        "ls = Lasso(alpha=best_alpha, max_iter=100000, tol = 0.000001)\n",
        "ls.fit(X_stand, y_7)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=1.011080808080808, copy_X=True, fit_intercept=True, max_iter=100000,\n",
              "      normalize=False, positive=False, precompute=False, random_state=None,\n",
              "      selection='cyclic', tol=1e-06, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LptBHgRGcoi",
        "outputId": "b089d1cd-6ff2-4521-dd27-6b6868d1ce0e"
      },
      "source": [
        "# Coefficient doesn't resemble model at all. But these have been\n",
        "#scaled by their std. must divide by std\n",
        "ls.coef_"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0000000e+00,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "       -0.0000000e+00,  0.0000000e+00, -4.1948691e+02,  0.0000000e+00,\n",
              "       -2.6710119e-01,  0.0000000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej-_C-9zGimC",
        "outputId": "2fa8dfa8-dd84-4c69-b42c-40902c708104"
      },
      "source": [
        "# That's better - very close to actual value of -1\n",
        "ls.coef_ / x.std()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
              "       -0.00000000e+00,  0.00000000e+00, -3.97145674e+02,  0.00000000e+00,\n",
              "       -2.52875786e-01,  0.00000000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWdxeyZGqhC",
        "outputId": "2d173315-804c-4dcd-8f38-f5910eb70fe2"
      },
      "source": [
        "# Also look at the intercept\n",
        "ls.intercept_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.24937081563278"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmdg_0S4GyFc"
      },
      "source": [
        "### **Question Nine**\n",
        "\n",
        "In this excercise, we will predict the number of college applications received using the other variables in the `College` dataset.\n",
        "\n",
        "A. Split the dataset into a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9X5v0dLG8yN"
      },
      "source": [
        "college = pd.read_csv('https://raw.githubusercontent.com/emredjan/ISL-python/master/datasets/College.csv')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "EkwzJ6SnHIJF",
        "outputId": "08f39a50-d04f-434f-ee7b-4b256bd6bdd0"
      },
      "source": [
        "college.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Private</th>\n",
              "      <th>Apps</th>\n",
              "      <th>Accept</th>\n",
              "      <th>Enroll</th>\n",
              "      <th>Top10perc</th>\n",
              "      <th>Top25perc</th>\n",
              "      <th>F.Undergrad</th>\n",
              "      <th>P.Undergrad</th>\n",
              "      <th>Outstate</th>\n",
              "      <th>Room.Board</th>\n",
              "      <th>Books</th>\n",
              "      <th>Personal</th>\n",
              "      <th>PhD</th>\n",
              "      <th>Terminal</th>\n",
              "      <th>S.F.Ratio</th>\n",
              "      <th>perc.alumni</th>\n",
              "      <th>Expend</th>\n",
              "      <th>Grad.Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abilene Christian University</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1660</td>\n",
              "      <td>1232</td>\n",
              "      <td>721</td>\n",
              "      <td>23</td>\n",
              "      <td>52</td>\n",
              "      <td>2885</td>\n",
              "      <td>537</td>\n",
              "      <td>7440</td>\n",
              "      <td>3300</td>\n",
              "      <td>450</td>\n",
              "      <td>2200</td>\n",
              "      <td>70</td>\n",
              "      <td>78</td>\n",
              "      <td>18.1</td>\n",
              "      <td>12</td>\n",
              "      <td>7041</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelphi University</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2186</td>\n",
              "      <td>1924</td>\n",
              "      <td>512</td>\n",
              "      <td>16</td>\n",
              "      <td>29</td>\n",
              "      <td>2683</td>\n",
              "      <td>1227</td>\n",
              "      <td>12280</td>\n",
              "      <td>6450</td>\n",
              "      <td>750</td>\n",
              "      <td>1500</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>12.2</td>\n",
              "      <td>16</td>\n",
              "      <td>10527</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adrian College</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1428</td>\n",
              "      <td>1097</td>\n",
              "      <td>336</td>\n",
              "      <td>22</td>\n",
              "      <td>50</td>\n",
              "      <td>1036</td>\n",
              "      <td>99</td>\n",
              "      <td>11250</td>\n",
              "      <td>3750</td>\n",
              "      <td>400</td>\n",
              "      <td>1165</td>\n",
              "      <td>53</td>\n",
              "      <td>66</td>\n",
              "      <td>12.9</td>\n",
              "      <td>30</td>\n",
              "      <td>8735</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Agnes Scott College</td>\n",
              "      <td>Yes</td>\n",
              "      <td>417</td>\n",
              "      <td>349</td>\n",
              "      <td>137</td>\n",
              "      <td>60</td>\n",
              "      <td>89</td>\n",
              "      <td>510</td>\n",
              "      <td>63</td>\n",
              "      <td>12960</td>\n",
              "      <td>5450</td>\n",
              "      <td>450</td>\n",
              "      <td>875</td>\n",
              "      <td>92</td>\n",
              "      <td>97</td>\n",
              "      <td>7.7</td>\n",
              "      <td>37</td>\n",
              "      <td>19016</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alaska Pacific University</td>\n",
              "      <td>Yes</td>\n",
              "      <td>193</td>\n",
              "      <td>146</td>\n",
              "      <td>55</td>\n",
              "      <td>16</td>\n",
              "      <td>44</td>\n",
              "      <td>249</td>\n",
              "      <td>869</td>\n",
              "      <td>7560</td>\n",
              "      <td>4120</td>\n",
              "      <td>800</td>\n",
              "      <td>1500</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "      <td>11.9</td>\n",
              "      <td>2</td>\n",
              "      <td>10922</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Unnamed: 0 Private  Apps  ...  perc.alumni  Expend  Grad.Rate\n",
              "0  Abilene Christian University     Yes  1660  ...           12    7041         60\n",
              "1            Adelphi University     Yes  2186  ...           16   10527         56\n",
              "2                Adrian College     Yes  1428  ...           30    8735         54\n",
              "3           Agnes Scott College     Yes   417  ...           37   19016         59\n",
              "4     Alaska Pacific University     Yes   193  ...            2   10922         15\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvsleBHiHMkH",
        "outputId": "6cc6df31-d488-49a5-e9a7-665c6152fe74"
      },
      "source": [
        "college['Private'].value_counts()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yes    565\n",
              "No     212\n",
              "Name: Private, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RXd3mSSHRnZ"
      },
      "source": [
        "college['private_yes'] = (college['Private'] == 'Yes') *1"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHu6tJQqHX-s"
      },
      "source": [
        "X = college.iloc[:, 3:]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3_ZnA7VHa1S"
      },
      "source": [
        "y = college['Apps']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xm0BT5KHdkg"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2BXV6z-HjHK"
      },
      "source": [
        "B. Fit a linear model using least squares on the training set and report the test error obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyKWO77rHpJM",
        "outputId": "f610be13-8d65-4983-a212-93661bea4393"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcqXG8fLHu5n",
        "outputId": "679a54f2-57b5-40c3-a537-e1abf5a24d54"
      },
      "source": [
        "# Error\n",
        "np.mean((lr.predict(X_test) - y_test)**2)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1896943.9602660863"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXNkshZtH1pu"
      },
      "source": [
        "C. Fit a ridge regression model on the training set, with $\\lambda$ chosen by cross-validattion. Report the test error obtained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_tUDd2hH9HQ"
      },
      "source": [
        "from sklearn.linear_model import RidgeCV"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN-H-jf0ICpL"
      },
      "source": [
        "X_std = X.iloc[:, :-1].std()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3wiiYUYIGB1"
      },
      "source": [
        "X_std['private_yes'] = 1"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B-XLc0IIMzo",
        "outputId": "adee291e-6fef-46ff-de12-545188fa15ae"
      },
      "source": [
        "X_std"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accept         2451.113971\n",
              "Enroll          929.176190\n",
              "Top10perc        17.640364\n",
              "Top25perc        19.804778\n",
              "F.Undergrad    4850.420531\n",
              "P.Undergrad    1522.431887\n",
              "Outstate       4023.016484\n",
              "Room.Board     1096.696416\n",
              "Books           165.105360\n",
              "Personal        677.071454\n",
              "PhD              16.328155\n",
              "Terminal         14.722359\n",
              "S.F.Ratio         3.958349\n",
              "perc.alumni      12.391801\n",
              "Expend         5221.768440\n",
              "Grad.Rate        17.177710\n",
              "private_yes       1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLJS_QaCIPCh",
        "outputId": "6533f195-525a-4636-af53-2e5ed5ef71ad"
      },
      "source": [
        "rcv = RidgeCV(alphas = np.linspace(0.01, 100, 1000), cv=10)\n",
        "rcv.fit(X / X_std, y)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeCV(alphas=array([1.00000000e-02, 1.10090090e-01, 2.10180180e-01, 3.10270270e-01,\n",
              "       4.10360360e-01, 5.10450450e-01, 6.10540541e-01, 7.10630631e-01,\n",
              "       8.10720721e-01, 9.10810811e-01, 1.01090090e+00, 1.11099099e+00,\n",
              "       1.21108108e+00, 1.31117117e+00, 1.41126126e+00, 1.51135135e+00,\n",
              "       1.61144144e+00, 1.71153153e+00, 1.81162162e+00, 1.91171171e+00,\n",
              "       2.01180180e+00, 2.11189189e+0...\n",
              "       9.80982883e+01, 9.81983784e+01, 9.82984685e+01, 9.83985586e+01,\n",
              "       9.84986486e+01, 9.85987387e+01, 9.86988288e+01, 9.87989189e+01,\n",
              "       9.88990090e+01, 9.89990991e+01, 9.90991892e+01, 9.91992793e+01,\n",
              "       9.92993694e+01, 9.93994595e+01, 9.94995495e+01, 9.95996396e+01,\n",
              "       9.96997297e+01, 9.97998198e+01, 9.98999099e+01, 1.00000000e+02]),\n",
              "        cv=10, fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
              "        store_cv_values=False)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}
